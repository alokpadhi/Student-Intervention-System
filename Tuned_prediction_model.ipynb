{
  "cells": [
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "collapsed": true,
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": false
      },
      "cell_type": "markdown",
      "source": "# Getting Started"
    },
    {
      "metadata": {
        "_uuid": "30990b61a2de0d1e643215c516fccd1921f16fc3"
      },
      "cell_type": "markdown",
      "source": "Goal of the project: To identify students who might need early intervention i.e to predict whether the student will pas or fail.\n\nThe dataset: Let's see the columns of the dataset.\n\n* school:  \"student's school\",\n* sex: \"student's sex\",\n* age: \"student's age\"\n* address: \"student's home address type\"\n* famsize: \"family size\"\n* Pstatus: \"parent's cohabitation status\"\n* Medu: \"mother's education\"\n* Fedu: \"father's education\"\n* Mjob: \"mother's job\"\n* Fjob: \"father's job\"\n* reason: \"reason to choose this school\"\n* guardian: \"student's guardian\"\n* traveltime: \"home to school travel time\"\n* studytime: \"weekly study time\"\n* failures: \"number of past class failures\"\n* schoolsup: \"extra educational support\"\n* famsup: \"family educational support\"\n* paid: \"extra paid classes within the course subject\"\n* activities: \"extra-curricular activities\"\n* nursery: \"attended nursery school\"\n* higher: \"wants to take higher education\"\n* internet: \"Internet access at home\"\n* romantic: \"with a romantic relationship\"\n* famrel: \"quality of family relationships\"\n* freetime: \"free time after school\"\n* goout: \"going out with friends\"\n* Dalc: \"workday alcohol consumption\"\n* Walc: \"weekend alcohol consumption\"\n* health: \"current health status\"\n* absences: \"number of school absences\"\n* passed\": \"did the student pass the final exam\""
    },
    {
      "metadata": {
        "_uuid": "4a2a14b596be4d56fe55240a74d2ded9038df985"
      },
      "cell_type": "markdown",
      "source": "So we do have all total 30 featres to predict whether a student pass or fail.  so the target variable is \"passed\". Now it's time to explore the data.\n"
    },
    {
      "metadata": {
        "_uuid": "8a800c7cd2b2b45ed236e6324f4373484c3c8603"
      },
      "cell_type": "markdown",
      "source": "# Data Exploration"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "6581d4be56cff3ee4a631ac31db57aa8c1ffd82d"
      },
      "cell_type": "code",
      "source": "# importing librararies\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.tree import DecisionTreeClassifier, export_graphviz\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import GaussianNB\n\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import f1_score, make_scorer\n\n%load_ext autoreload\n%autoreload 2\n\n%matplotlib inline\nplt.style.use('ggplot')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "cdb5af8276a3316669c11ca5be303a79168ac2f0"
      },
      "cell_type": "code",
      "source": "# reading the data\nstudent_data = pd.read_csv('../input/student-data.csv')\ndisplay(student_data.head())",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "07702b7efc87757448196107d78e32a4be737450"
      },
      "cell_type": "markdown",
      "source": "## Finding out the following\n* Total number of students\n* Total numbe of students passed and failed\n* Total number of features\n* Graduation rate of the class"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "cb9439d750d4c68d27cc84297bfd53695c803e15",
        "scrolled": true
      },
      "cell_type": "code",
      "source": "n_students = student_data.shape[0]\nstud_passed = student_data['passed'].value_counts().loc['yes']\nstud_failed = student_data['passed'].value_counts().loc['no']\nn_features = student_data.shape[1]\ngrad_rate = ( stud_passed / float(stud_passed + stud_failed) ) * 100\nprint(\"Number of students: \", n_students)\nprint(\"Number of students passed: \", stud_passed)\nprint(\"Number of students failed: \", stud_failed)\nprint(\"Total number of features: \", n_features)\nprint(\"Graduation rate: \", round(grad_rate, 2))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "89a850b192f5b2ed0c08604ef97ea5e9c7adfc53"
      },
      "cell_type": "markdown",
      "source": "# Prepare the data"
    },
    {
      "metadata": {
        "_uuid": "fa01fd7454b45925c1918a84bf45c1c6ac83afa8"
      },
      "cell_type": "markdown",
      "source": "Divide our dataset into features and target, so for us the target columns is 'passed'. \n1. Split dataset into features and target \n2. Converting non-numeric columns to numeric\n3.  Spliting the whole dataset into training and testing \n"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "35f13b99c2b65af1db507ebffbd5c5d120502fc0"
      },
      "cell_type": "code",
      "source": "X_feature = student_data.drop('passed', axis='columns')\ny_target = student_data['passed']\n\nfeatures = list(X_feature.columns)\ntarget = student_data.columns[-1]\n\nprint(\"Features are: \")\nfor i, feature in enumerate(features):\n    print(i+1, \" \", feature)\n    \nprint(\"\\nTarget is: \", target)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "7f6d0394c55f59911a804c581fef936d9360eddb"
      },
      "cell_type": "markdown",
      "source": "## Preprocessing features"
    },
    {
      "metadata": {
        "_uuid": "fa238286cdeb92a6d6f29c2bae1989981bdc5897"
      },
      "cell_type": "markdown",
      "source": "As we can see, there are several features which are non-numeric. And some features are categorical variable . To handle those categorical variable we will use pandas get_dummies() to create dummy variables and columns with binary variables to 0/1."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "28609a149eeb6259294ff6808d788912fd4f27b1"
      },
      "cell_type": "code",
      "source": "def preprocess_features(X_feature):\n    \"\"\"Convert binary value features into 0/1 and categorical non numeric variables to dummy variables\"\"\"\n    \n    # initialize the new dataframe i.e output\n    output_df = pd.DataFrame(index=X_feature.index)\n    \n    # iterate through each feature column\n    for col, col_data in X_feature.iteritems():\n        if col_data.dtype == object:\n            col_data = col_data.replace(['yes', 'no'], [1, 0])\n        if col_data.dtype == object:\n            col_data = pd.get_dummies(col_data, prefix=col)\n            \n        output_df = output_df.join(col_data)\n    \n    return output_df\nX_feature = preprocess_features(X_feature)\nprint(\"Number of columns after precprocessing: {}, \\n{}\".format(len(X_feature.columns), \n                                                                list(X_feature.columns)))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "2b6e35ad55f02a578399003c108967537b4f61ba"
      },
      "cell_type": "markdown",
      "source": "## Splitting data into train and test set"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f0ea42ad2115a3d78383095a6dd3fff7ecf3fc04"
      },
      "cell_type": "code",
      "source": "from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X_feature, y_target, test_size = 0.25, \n                                                    stratify=y_target, random_state=42)\nprint(\"Training set size: {}\".format(len(X_train)))\nprint(\"Test set size: {}\".format(len(X_test)))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "ca680044f3226e157947f899f991b46fa209071d"
      },
      "cell_type": "markdown",
      "source": "# Exploratory Data Analysis"
    },
    {
      "metadata": {
        "_uuid": "21a4a437dcfc0006f7f955ef62a2250f98212211"
      },
      "cell_type": "markdown",
      "source": "Now we have a separate test set and we are not going to touch that until we found a good model to testify. Untill that time let's explore what the training data has to offer."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "0bfaf841b18ebcde42f6400ee94377b2e1f0ac03"
      },
      "cell_type": "code",
      "source": "def plot_categorical(df, count_col='passed', plots_per_row=3):\n    df_cat = df.select_dtypes(include=['object'])\n    \n    for i, col in enumerate(df_cat.columns):\n        plot_index = i % plots_per_row\n        \n        if plot_index == 0:\n            f, axes = plt.subplots(1, plots_per_row, figsize=(15, 5))\n            sns.despine(left=True)\n        sns.countplot(x=col, hue=count_col, data=df, ax=axes[plot_index])\n        \n        ",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "06698ee7276b32391f19633e0e9853402c841d50"
      },
      "cell_type": "code",
      "source": "df = student_data.iloc[:296, :]\nplot_categorical(df)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "95297a5d262d9e1f4cbba723ddd80249dcde27bb"
      },
      "cell_type": "markdown",
      "source": "A nice visualiztion to understand how these variables varies with our target class labels.\n* Look at the internet feature, the distibution is not balanced at all, those who have an internet connection are passed twice as of those who haven't passed. So as those who havenot internet connection the number of student pass is more than number of student failed. So in both cases these seems to draw same conclusion which leads no where.\n* Let's take the higher education feature, students wants to persue higher education has higher chance of passing the exam compared to a negligible count for those who wants to persue higher education but somehow failed.\n* Have a look at the paid feature, which tells us about student subscribe to extra paid classes, in that if we look at the graph then either student took paid courses or not the number of passing is more in both the cases. So then it barely determines whether a student will pas or fail. Because whether a student took paid course or not the number of passing and failing count is almost same in both cases.\n\nLike this many interesting information can be obtained from this graph. But the problem is we really cant determine which feature lead to where. In that case a good predictive model can tells us the answer. Before that let's have a look at the numeric variables."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f79fb03dc42850867de1ec53539d8785f4e9c1a2"
      },
      "cell_type": "code",
      "source": "def plot_numeric(df, col_t='passed', plots_per_row=2):\n    df_num = df.select_dtypes(exclude=object)\n    \n    if not (col_t in df_num.columns):\n        df_num = df_num.join(df[col_t])\n    \n    for i, col in enumerate(df_num.columns):\n        if col == col_t:\n            continue\n        plot_idx = i % plots_per_row\n        \n        if plot_idx == 0:\n            f, axes = plt.subplots(1, plots_per_row, figsize=(15, 5))\n            sns.despine(left=True)\n            \n        # separating dataframe into pass and fail\n        df_num_yes = df_num.loc[df_num[col_t] == 'yes']\n        yes_label = '{0} - passed'.format(col)\n        \n        df_num_no = df_num.loc[df_num[col_t] == 'no']\n        no_label = '{0} - Failed'.format(col)\n        \n        sns.kdeplot(df_num_yes[col], ax=axes[plot_idx], shade=True, label=yes_label)\n        sns.kdeplot(df_num_no[col], ax=axes[plot_idx], shade=True, label=no_label)\n        \n        axes[plot_idx].set_title('Distribution of \"{0}\" \\nfactored by \"{1}\"\\nFeature:\"{2}\"  Target:\"{3}\"'\n                                 .format(col, col_t, col, col_t))\n        axes[plot_idx].set(xlabel=col)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "26640246eea4c77bc0c3e01d0f839ae3d15071a9"
      },
      "cell_type": "code",
      "source": "plot_numeric(df)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "0141da75368649d14cc016a234ecb1038cc5e5b3"
      },
      "cell_type": "markdown",
      "source": "* Young students have a high probability of pass the exam while the graph shows studuent with age above 20 has a lower probability of failure.\n* Student's mother having a higher education tells us that the student have greater chance of getting passed whereas student's mother having a primary education says that it has greater chance to get failed in exam.\n* Is travel time a key factor? Yes but in this case it doesn't say much. As student travels less distance have higher probability of getting passed while the other side tells us that the mass distribution for less travel time with failed has also bit higher probability not as high as passed but it has.\n\nWe discovered both categorical and numerical distribution now let's build model to testify."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c500160b06edc7a7abea8d0b17669921de1892e6"
      },
      "cell_type": "markdown",
      "source": "# Training and Evaluating models"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "531188107b0b081f2af56f4c42de76d6fb99d62d"
      },
      "cell_type": "code",
      "source": "# Training a model\nimport time\n\ndef train_classifier(clf, X_train, y_train, verbose=True):\n    \"\"\"\n    Trains a classifier that is passed in to this function\n    \n    :param clf: sklearn model object\n    :param X_train: feature dataframe object\n    :param y_train: target variables\n    :param verbose: flag to print training information\n    \"\"\"\n    start = time.time()\n    clf.fit(X_train, y_train)\n    end = time.time()\n    train_time = end - start\n    \n    if verbose:\n        print(\"Trained: {}\".format(clf.__class__.__name__))\n        print(\"Training time (secs)\".format(train_time))\n        \n    return clf, train_time",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "5157ad678855cef039c21924f3bc7ec1e76f221a"
      },
      "cell_type": "code",
      "source": "# predictions on provided training and testing data set\ndef predict_labels(clf, features, target, verbose=True):\n    \"\"\"\n    Predicts and calculate the f1_score for the given feature set using provided target values\n    \n    :param clf: sklearn model object\n    :param features: feature set values\n    :param target: target values\n    \n    \"\"\"\n    \n    start = time.time()\n    y_pred = clf.predict(features)\n    end = time.time()\n    \n    prediction_time = end - start\n    \n    if verbose:\n        print(\"predicted labels using {}\".format(clf.__class__.__name__))\n        print(\"Prediction time: {}\".format(prediction_time))\n        \n    f1_measure = f1_score(target.values, y_pred, pos_label='yes')\n    \n    return f1_measure, prediction_time",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "524a15ac7bffee8fcf9fa8ded63cd1f11b3af0fa"
      },
      "cell_type": "code",
      "source": "def train_evaluate(clf, X_train, y_train, X_test, y_test, verbose=True):\n    \"\"\"\n    Training and evaluation on training and test dataset\n    :param clf: sklearn classfier object\n    :param X_train: training feature dataset\n    :param y_train: training target set\n    :param X_test: test feature set\n    :param y_test: test labels\n    \"\"\"\n    \n    clf, train_time = train_classifier(clf, X_train, y_train, verbose=verbose)\n    train_f1, train_pred_time = predict_labels(clf, X_train, y_train, verbose=verbose)\n    test_f1, test_pred_time = predict_labels(clf, X_test, y_test, verbose=verbose)\n    \n    print(\"F1 score on training set: {}\".format(train_f1))\n    print(\"F1 score on test set: {}\".format(test_f1))\n    \n    f1_scores = {'F1_train': train_f1,\n                'F1_test': test_f1}\n    \n    timings = {\n        \"Training_time\": train_time,\n        \"prediction_train_time\": train_pred_time,\n        \"prediction_test_time\": test_pred_time\n    }\n    \n    return clf, f1_scores, timings",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "94f17dd168979a14adf4807d3f39d7bfcf0ec514"
      },
      "cell_type": "code",
      "source": "def subset_train_predict(clf, X_train, y_train, X_test, y_test, subset_sizes, verbose=False):\n    df_rows = []\n    \n    for i in subset_sizes:\n        row = {'training_size': i}\n        \n        X_train_subset = X_train[:i]\n        y_train_subset = y_train[:i]\n        \n        clf, f1_scores, timings = train_evaluate(clf, X_train, y_train, X_test, y_test, verbose=verbose)\n        \n        row.update(f1_scores)\n        row.update(timings)\n        \n        df_rows.append(row)\n        \n    return pd.DataFrame(df_rows)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "145568f192e383e590320b38a33e7d7ad5e4af89"
      },
      "cell_type": "code",
      "source": "def plot_computation_time(df):\n    fig, ax = plt.subplots(figsize=(12, 9))\n    _ = ax.plot(df.training_size, df.Training_time, label=\"Training time\")\n    _ = ax.plot(df.training_size, df.prediction_train_time, label='Prediction time - Train')\n    _ = ax.plot(df.training_size, df.prediction_test_time, label='Predtiction time - Test')\n    _ = ax.legend(loc='upper-left')\n    ax.set_xticks(subset_sizes)\n    ax.set_xticklabels(subset_sizes, rotation=45)\n    ax.set_xlabel('Training set size')\n    ax.set_ylabel('seconds')\n    ax.set_title('Training/Prediction times')\n    plt.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "77c0056734a505241d05d9862d7c290e9ca3a567"
      },
      "cell_type": "code",
      "source": "def plot_f1_scores(df):\n    fig, ax = plt.subplots(figsize=(12, 9))\n    _ = ax.plot(df.training_size, df.F1_train, label='F1 scores - Training')\n    _ = ax.plot(df.training_size, df.F1_test, label='F1 scores - Testing')\n    _ = ax.legend(loc='upper-left')\n    ax.set_xticks(subset_sizes)\n    ax.set_xticklabels(subset_sizes, rotation=45)\n    ax.set_xlabel('Training set size')\n    ax.set_ylabel('F1 score')\n    ax.set_title('F1 scores of each training samples')\n    plt.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "29db5866a25aee878b8946ccc526eb29dcc56e59"
      },
      "cell_type": "markdown",
      "source": "## Decision Tree"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "265ed5d1a992bddad3f105eeb1345dde1443d8c4"
      },
      "cell_type": "code",
      "source": "subset_sizes = range(100, 301, 10)\ntree_model = subset_train_predict(DecisionTreeClassifier(), X_train, y_train,\n                                 X_test, y_test, subset_sizes=subset_sizes)\ntree_model",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "6062e50149cb938abb91738f482dbe9cf4127dd3"
      },
      "cell_type": "code",
      "source": "def plot_tree(tree_model, feature_names):\n    with open(\"tree.dot\", 'w') as f:\n        export_graphviz(tree_model, out_file=f,\n                       impurity=False,\n                       rounded=True, \n                       filled=True,\n                       leaves_parallel=False,\n                       feature_names=feature_names, \n                       class_names=['fail', 'pass'])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a79e7c6dc39ea30277dd037c38ba3f66f514b2c0"
      },
      "cell_type": "code",
      "source": "tree_stats = tree_model[20:21]\n#tree_model.columns\nplot_computation_time(tree_model)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "066e089350519dc6dcd2f1b81b2c4cdc00c30181"
      },
      "cell_type": "code",
      "source": "plot_f1_scores(tree_model)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "2a3fcbc1acfaaa64a561daa3a662d6d3a58ad022"
      },
      "cell_type": "code",
      "source": "tree_model, _, _ = train_evaluate(DecisionTreeClassifier(),\n                                 X_train, y_train,\n                                 X_test, y_test,\n                                 verbose=False)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "701ec0bcb6140555f9a15b247114052554620ec6"
      },
      "cell_type": "code",
      "source": "plot_tree(tree_model, X_train.columns)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "5242ca1837741884ef2e5e5ad1f411dccf0adaec"
      },
      "cell_type": "code",
      "source": "%%bash\n\ndot -Tpng tree.dot -o tree.png",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "7471a71921e32f1351701ae5fa68f4be782ff9e8"
      },
      "cell_type": "code",
      "source": "from IPython.display import Image\nImage(filename='tree.png', width=920, height=1280)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "14d62178a0a04b7da6e5cc6e6df3e23a5e111045"
      },
      "cell_type": "markdown",
      "source": "# Random Forest"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "06dd6719e0713e1676438625eec5e302de2a952b"
      },
      "cell_type": "code",
      "source": "subset_sizes = range(100, 301, 10)\n\nrf_model = subset_train_predict(RandomForestClassifier(),\n                                         X_train, y_train,\n                                         X_test, y_test,\n                                         subset_sizes=subset_sizes)\nrf_model",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "4193b8a229ac0ac708e1ae21baecee4befc29b3c"
      },
      "cell_type": "code",
      "source": "plot_computation_time(rf_model)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "dcb220ce2a40a3c88ea2889d88d7a790615ae5ba"
      },
      "cell_type": "code",
      "source": "plot_f1_scores(rf_model)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "68fb456137c36453c91ff01602b6b7162fb0ee68"
      },
      "cell_type": "code",
      "source": "rf_model, _, _ = train_evaluate(RandomForestClassifier(), X_train, y_train,\n                               X_test, y_test, verbose=False)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "093919df4b3b4e0a6044ff921e13b3481cc99730"
      },
      "cell_type": "code",
      "source": "rf_importances = pd.DataFrame({'Feature': X_train.columns, \n                               'Importance': rf_model.feature_importances_}, \n                             index=X_train.columns)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a48a230a31178f5c7fbe07a5249120b5fa0750ab"
      },
      "cell_type": "code",
      "source": "rf_importances.sort_values(by='Importance',\n                           ascending=False).plot(kind='bar', \n                                                 figsize=(16, 10),\n                                                 title='Feature Importance')\nplt.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f9f2cf3ae718c3a852ff8198c0344382a0711c09"
      },
      "cell_type": "markdown",
      "source": "If we look at the feature bars then one obvious features are absences and failures. After all if carry a hypothesis to predict one student's result for the next exam then we will first ask these questions, \n1. How many days that student present in the class?\n2. How is his result in the past exams, did he passed or failed from last couple of exams?"
    },
    {
      "metadata": {
        "_uuid": "148994fea9d04824268e1e86475a0db5db1f70f5"
      },
      "cell_type": "markdown",
      "source": "# Logistic Regression"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "80eb42779faf81d7258b1cbf201ff5b99a92e72a"
      },
      "cell_type": "code",
      "source": "# As it is a linear model, and to get the best we need to have all feature in the same scale\nfrom sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler().fit(X_train)\n\nX_train_scaled = scaler.transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\nX_train_scaled = pd.DataFrame(X_train_scaled, columns=X_train.columns)\nX_test_scaled = pd.DataFrame(X_test_scaled, columns=X_test.columns)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "65b4c632829ea2935acd987cbb868b39e0f2ac64"
      },
      "cell_type": "code",
      "source": "subset_sizes = range(100, 301, 10)\n\nlr_model = subset_train_predict(LogisticRegression(),\n                               X_train, y_train,\n                               X_test, y_test,\n                               subset_sizes=subset_sizes)\nlr_model",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "93bf1340e24fff4505087f0196971b80720e276a"
      },
      "cell_type": "code",
      "source": "plot_computation_time(lr_model)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "3142e585b1663950b2c70470dbb3c3bb87df2eb5"
      },
      "cell_type": "code",
      "source": "plot_f1_scores(lr_model)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "078930e5189daa98518c1daf92f2afd03f15dfad"
      },
      "cell_type": "markdown",
      "source": "[ISSUE]: That's really strange as the f1 score on every subset of test data is 0.75 from start to end, How this could be possible.\n"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "6889ec83a02a012b0fc57371a5cb208a2e4d19f8"
      },
      "cell_type": "code",
      "source": "lr_models, _, _ = train_evaluate(LogisticRegression(penalty='l1'),\n                               X_train_scaled, y_train,\n                               X_test_scaled, y_test,\n                               verbose=False)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "8106fc4894b58651f980f8f3a9210173e26015b6"
      },
      "cell_type": "code",
      "source": "lr_coeffs = pd.DataFrame({'Feature': X_train.columns, \n                          'Coefficient': np.abs(lr_models.coef_[0])}, \n                             index=X_train.columns)\n\nlr_coeffs.sort_values(by='Coefficient', \n                      ascending=False).plot(kind='bar',\n                                            figsize=(16, 10),\n                                            color='#cd7058',\n                                            title='Logistic Regression Coefficients with L1 penalty')\nplt.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "07603dab74dca11732f62b8b9471253c12a90e44"
      },
      "cell_type": "code",
      "source": "# let's look at +ve and -ve feature relevance score\nlr_fe_coeffs = pd.DataFrame({'Feature': X_train.columns, \n                          'Coefficient': lr_models.coef_[0]}, \n                             index=X_train.columns)\n\nlr_fe_coeffs.sort_values(by='Coefficient', \n                      ascending=False).plot(kind='bar',\n                                            figsize=(16, 10),\n                                            color='#cd7058',\n                                            title='Logistic Regression Coefficients with L1 penalty')\nplt.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "70311880c296b3160350d1eb613622ec78baf153"
      },
      "cell_type": "markdown",
      "source": "So failures is actually negetively effect the prediction."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "2581c03815f84a65c086c953dec0db6d17676cbf"
      },
      "cell_type": "code",
      "source": "# positively corelated features\nlr_fe_coeffs.sort_values(by='Coefficient', ascending=False).head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "fa874491ac3b817aa30f144c25ceca5bca6acae8"
      },
      "cell_type": "code",
      "source": "# negetively corelated features\nlr_fe_coeffs.sort_values(by='Coefficient', ascending=False).tail()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "916ea0dfa16f903a7127af06f06cab2eb82726a6"
      },
      "cell_type": "markdown",
      "source": "# Optimizing Models"
    },
    {
      "metadata": {
        "_uuid": "4557162dc9c6eb99b2acd97fd60ac4b79fc9a85b"
      },
      "cell_type": "markdown",
      "source": "## Decision Tree Fine Tuned"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "2c0cdc6f2bdcf447a6d8eb42be94fbb00dc07069"
      },
      "cell_type": "code",
      "source": "f1_scorer = make_scorer(f1_score, pos_label='yes')\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "2687e07e06c0534aeaee3a583b28f1677f5012e7"
      },
      "cell_type": "code",
      "source": "tree_param_grid = {\n    'criterion':['gini', 'entropy'],\n    'max_depth': [2, 3, 5, 7, 9],\n    'min_samples_split':[2, 10, 20, 30, 40],\n    'min_samples_leaf':[1, 2, 5, 10],\n    'max_features':[None, 'auto', 'sqrt', 1, 2, 5, 10]\n}\n\ntree_grid = GridSearchCV(DecisionTreeClassifier(), param_grid=tree_param_grid,\n                        scoring=f1_scorer, cv=5, n_jobs=-1, verbose=True)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "852638676deaa4f80a5a4a68bc6a3c0841900943"
      },
      "cell_type": "code",
      "source": "tree_grid.fit(X_train, y_train)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d1f43bbe43e1b89eca35df47c606f96be1d43887"
      },
      "cell_type": "code",
      "source": "print('Best cross-validated tuned F1 score for Decision Tree: {}'.format(tree_grid.best_score_))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "05fe416eadc9ea037c92554275571ee22d1f91c3"
      },
      "cell_type": "code",
      "source": "print(\"Choosen parameters are: {}\".format(tree_grid.best_params_))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "ce601424f41d661dccaa3c36c8a30a294ee24b01"
      },
      "cell_type": "code",
      "source": "plot_tree(tree_grid.best_estimator_, X_train.columns)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "207f2dcd7c85f7b550e26274e4a977036f9eb72d"
      },
      "cell_type": "code",
      "source": "%%bash\n\ndot -Tpng tree.dot -o tree.png",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e4e0e18c2a59263266cfd55666294f1fe4054cd8"
      },
      "cell_type": "code",
      "source": "from IPython.display import Image\nImage(filename='tree.png', width=920, height=1280)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "86f61b0aed4b81f191f853f885b81cde05319b21"
      },
      "cell_type": "code",
      "source": "dt_final, f1_dt_final, timing_dt_final = train_evaluate(DecisionTreeClassifier(**tree_grid.best_params_),\n                                          X_train, y_train,\n                                          X_test, y_test,\n                                          verbose=False)\n\ntree_tuned_stats = pd.DataFrame([f1_dt_final]).join(pd.DataFrame([timing_dt_final]))\ntree_tuned_stats",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "68123466eed59c733b780bc5898dcfb40f7b3b60"
      },
      "cell_type": "markdown",
      "source": "## Random Forest Fine Tuned"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "8ad0583370f462839c3e3d42c9f332ea098dc945"
      },
      "cell_type": "code",
      "source": "rf_params = {\n    'criterion': ['gini', 'entropy'],\n    'max_features': ['auto', 3, 5, 10, 20, 30, 40],\n    'max_depth': [None, 2, 4, 8, 12],\n    'n_estimators': [10, 50, 100, 500]\n}\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "8f38b596ee02492f0ce93e3c040eef119cf5431b"
      },
      "cell_type": "code",
      "source": "rf_grid = GridSearchCV(estimator=RandomForestClassifier(),\n                      param_grid=rf_params,\n                      scoring=f1_scorer,cv=5,\n                      n_jobs=-1, verbose=True)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "1aa522937eb2c05804accbd465229b4beb0cb86a"
      },
      "cell_type": "code",
      "source": "rf_grid.fit(X_train, y_train)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e26e4dcd42150585a66d9c9a183550af06925b47"
      },
      "cell_type": "code",
      "source": "print(\"Best cross validated tuned F1 score for Random Forest {}\".format(rf_grid.best_score_))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c7e38e90a6baa466d260fc89b4e03bea6a7d4915"
      },
      "cell_type": "code",
      "source": "print(\"Best choosen parameters: {}\".format(rf_grid.best_params_))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "4005857cab94768d01fd7a6e0ebe7b679fb95a48"
      },
      "cell_type": "code",
      "source": "rf_importance_tuned = pd.DataFrame({'Importance': rf_grid.best_estimator_.feature_importances_,\n                                   'Feature': X_train.columns}).sort_values(by='Importance',\n                                                                            ascending=False)\nrf_importance_tuned.head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "4b3171603f0e928d68ca6eda117a4d9b3fce0fb3"
      },
      "cell_type": "code",
      "source": "rf_importance_tuned.index = rf_importance_tuned.Feature.values\nrf_importance_tuned.plot(kind='bar', figsize=(16, 10))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "1c2ac815c8bb4485df51bae93e5a4b9e477f7f13"
      },
      "cell_type": "code",
      "source": "rf_final, f1_rf_final, rf_timing_final = train_evaluate(RandomForestClassifier(**rf_grid.best_params_),\n                                                       X_train, y_train,\n                                                       X_test, y_test,\n                                                       verbose=False)\n\nrf_tuned_stats = pd.DataFrame([f1_rf_final]).join(pd.DataFrame([rf_timing_final]))\nrf_tuned_stats",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "dc725331052a584972c33b0b4f2f70c3c86fc132"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}